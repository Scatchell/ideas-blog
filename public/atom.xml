<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Thinking For ThoughtWorks]]></title>
  <link href="http://yoursite.com/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2013-11-18T23:03:18+03:00</updated>
  <id>http://yoursite.com/</id>
  <author>
    <name><![CDATA[Anthony Scatchell]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Cool Factor]]></title>
    <link href="http://yoursite.com/blog/2013/11/09/the-cool-factor/"/>
    <updated>2013-11-09T15:37:00+03:00</updated>
    <id>http://yoursite.com/blog/2013/11/09/the-cool-factor</id>
    <content type="html"><![CDATA[<p><em>(This post is still an unfinished draft)</em></p>

<p>I often find myself wondering about and/or having conversations concerning the classic breadth vs depth conundrum. To explain it with a quick example, let&rsquo;s say you have 100 hours to learn some things &ndash; and you could choose either to:</p>

<ul>
<li>Learn 15 different things given these 100 hours, but all of them only to a relatively shallow degree</li>
<li>Learn only 1 or 2 things with these 100 hours, but learning them to an extremely deep depth</li>
</ul>


<p>So, which would you choose? Especially working in the IT industry, one that changes particularly quickly (making the industry specific information seem inherently transient), this question becomes quite interesting.</p>

<h3>The Answer:</h3>

<p>If you ask this question to almost anyone, inside or out of the IT industry, you&rsquo;ll likely get the same answer. Can you guess what it is?</p>

<!-- more -->


<blockquote><p>&ldquo;A happy median between depth and breath!&rdquo;</p></blockquote>

<p>&hellip;or</p>

<blockquote><p>&ldquo;T-Shaped people, who are generalists amongst a wide array of skills but experts in only a few&rdquo;&#8221;</p></blockquote>

<p>Or other such answers of equally indescribable brilliance and specificity. I would like to make clear that I think this answer is <strong>bullshit</strong>, and that, in most cases, it should be viewed as nothing less.</p>

<p>It is valid and useful in the sense that perfection is an important ideology to <em>strive</em> for &ndash; of course we want to make an <em>attempt</em> to achieve the best possible solution. But, I also feel it&rsquo;s a bit like the president asking his or her chief economic advisor &ldquo;What should we do about balancing the budget?&rdquo; and getting the response &ldquo;We should make sure we don&rsquo;t waste money on bad things, and spend it only on good things!&rdquo; It&rsquo;s a nice idea that&rsquo;s really easy to agree with but, how helpful is it, really?</p>

<p>So, let us put aside the answer of &ldquo;be perfect&rdquo; and instead consider slightly more realistic concerns.</p>

<h3>The Slightly Less Bullshit Answer:</h3>

<p>In the IT industry, I believe there is an unspoken influence which places a stronger focus on depth than on breadth. I will also argue that I think this is wrong, and not only potentially dangerous to the industry as a whole, but also <em>particularly</em> dangerous to consulting firms &ndash; the reasoning of which I will try to detail shortly.</p>

<p>I feel safe suggesting such a hard opinion because I don&rsquo;t insult the general ideology of depth being &lsquo;better&rsquo; than breadth, but instead I insult the mechanism that I believe often causes this decision to be made <a onclick="$('#hidden-coolness').show()" style="cursor:pointer;">click to see:</a></p>

<div id="hidden-coolness" style="
display: none;
padding: 15px;
border: 4px dashed black;
">
    <h3>The Cool Factor</h3>

    <img src="http://yoursite.com/images/don_draper_is_cool.png" alt="The Cool Factor">
</div>


<p></br>
The cool factor can be explained with a simple example. Take two programming concepts:</p>

<p><strong><em>Concept A</em></strong>: Learning basic array manipulation in C, Java, Python, Ruby, JavaScript, etc.</p>

<hr />

<p><strong><em>Concept B</em></strong>: Knowing a low level pointer based programming language well enough to use pointer arithmetic to alter the values of an array tersely</p>

<p><em>Concept A</em> is something about any programmer will know, iterating and manipulating arrays in a variety of ways, i.e.</p>

<ul>
<li>Mapping an array to add 1 to every element</li>
<li>Initializing arrays with a set of values</li>
<li>Iterating and selecting a particular element from an array.</li>
</ul>


<p>This is a damn <strong>good</strong> idea. It&rsquo;s relatively simple, and has incredible utility with almost every program you might want to write.</p>

<p><em>Concept B</em> is something that fewer programmers know about. I also think we can safely say it is much less useful than Concept A. It&rsquo;s a more complex idea, and it&rsquo;s likely you will run into this technique only after working with a pointer based language for quite some time. Maybe most critically, it will only be legitimately useful (i.e. no other good way to solve the problem) in a comparatively minuscule number of cases.</p>

<p>Now &ndash; imagine you ask some fellow developer to tell you about some concept, any concept, concerning programming. What would be a &ldquo;cooler&rdquo; response?  If they responded with and explained <em>Concept A</em>, basic array manipulation, or <em>Concept B</em>, using pointer arithmetic to manipulate arrays? I think the answer is pretty obvious, it would be <strong>much</strong> cooler to tell someone a lesser known technique like Concept B.</p>

<p>Thus we describe a &ldquo;technical coolness&rdquo; of the two topics as follows:</p>

<p><img src="http://yoursite.com/images/technical_coolness.png" alt="Technical Coolness" /></p>

<p>(Admittedly not the best use of the word &lsquo;cool&rsquo; :-P)</p>

<p>This elucidates the &ldquo;cool factor&rdquo;, which is simply the following phenomenon:</p>

<h3>It&rsquo;s incredibly cool to know useless things.</h3>

<p>This is clearly illustrated in a few points:</p>

<ol>
<li>The more useless something is, the harder it is to learn and remember (it is seldom employed, and is so useless that it is rare to come by).</li>
<li>The harder it is to learn, the less people who will know it.</li>
<li>The less people who know a concept, the cooler it is to know (because you will be one of the few with this knowledge).</li>
</ol>


<p>Thus we can conclude: People are infinitely impressed by useless knowledge.</p>

<p>Think about it&hellip;if an idea is useful &ndash; truly useful &ndash; it inherently <strong>must</strong> spread like wildfire through an industry. In the software development industry things like mocking and stubbing, writing tests for large code bases, cloud based storage &ndash; these concepts spread incredibly easily and quickly.</p>

<p>Other concepts though, remain known by only a few. Why? Because for God&rsquo;s sake, they <em>shouldn&rsquo;t</em> spread. They are utterly useless in all but an extremely small subset of problems, and are not even close to ubiquitously applicable like the good ideas are. The frustrating part is, this seems to be exactly why they are so damn cool.</p>

<p>The cool factor seems to be particularly pervasive in the software industry, and I believe it&rsquo;s one of the reasons we often get people being more desirous of a very depth-full understand of tech, so they can obtain more of this deep, &ldquo;cool&rdquo; (useless) knowledge and impress others with that expertise. I also feel this is a serious problem that needs to be solved.</p>

<h3>Why is this an issue?</h3>

<p>Lots of reasons! The critical one being it drives people toward spending their valuable (and limited) time learning useless but impressive technical concepts, and the coolness of these topics leads them to in turn spread via conversation throughout the industry much more quickly and efficiently than they actually should. The waste of time learning useless knowledge is one issue but, even worse is when people start to actually <strong>use</strong> these concepts just because they think they are so cool. This leads us to employ tools and techniques to solve problems they have absolutely no place in. I.E. writing a large project in vim with all the &ldquo;refactoring tools&rdquo; vim macro&rsquo;s built by hand. Cool? Definitely. Useful and time saving? I think quite the opposite (coming from someone writing this post in vim).</p>

<p>Further, this would be especially destructive in a team of 10 people where only 5 are vim ninja&rsquo;s and the other 5 are just &lsquo;pretty good&rsquo; with the editor. A problem that won&rsquo;t be spoken about because, of course, the 5 who are weaker at vim will be disincentivized from speaking up&hellip;due to the incredibly uncool nature of suggesting a fat, memory intensive IDE.</p>

<p>I also think the problem is particularly dangerous in the consulting industry. As much as we hate it, we are not there to show off how many awesome, bad ass tools and techniques we can use in a project. Instead, we&rsquo;re there to solve some problem as quickly, efficiently, and most important: <strong>simply</strong> as possible. This is in an effort to get code quickly in working order, easy to change, and easily handed over to our clients. Bringing <a href="https://code.google.com/p/guava-libraries/wiki/FunctionalExplained">guava</a> into a project, and upgrading to Java 8 so we can use a hash whose values are functions to solve a relatively simple sorting problem is cool, but is it really necessary? Is it really the simplest and easiest thing we can do to solve that sorting issue for our clients?</p>

<h3>So, what to do?</h3>

<p>Per the norm, exposing and ridiculing a problem is infinitely easier (and more fun :-P) than actually offering solutions for it. But, to give it a shot:</p>

<ol>
<li>When you hear about an idea that seems incredibly cool &ndash; stop yourself from exploding in excitement and:</li>
<li>Try to think of two good ways to use the idea to solve problems you&rsquo;ve had before in a way that&rsquo;s significantly better than using other tools</li>
<li>Consider if you would be to understand the concept if you had absolutely no idea what it was, but saw it in the code</li>
<li>If you can&rsquo;t do both of the above (think of two ways or understand the concept directly when seeing it) &ndash; then no matter how cool it is, don&rsquo;t use it :-P</li>
<li>Have someone review your code from time to time. If it takes them more than a few minutes to understand a certain part, it might be due to the unnecessary complexity of some tool or technique you are using there. This one is dangerous, because the reviewer very well may say &ldquo;Wow, that is AWESOME!&rdquo; once they figure out what the hell is going on but, keep in mind, this is NOT GOOD &ndash; it is actually an indicator you should look more closely and make sure the coolness didn&rsquo;t blind your better judgement.</li>
<li>Start off with the simplest solution possible. If it works, and keeps the code extensible and easily changeable, avoid at all costs refactoring it to the &lsquo;cooler&rsquo; version.</li>
<li>Control yourself. If someone tells you of a new technology or tool that is cool as hell, for God&rsquo;s sake ONLY use it if it will really offer irreplaceable value in a particular situation. Don&rsquo;t be seduced by the coolness :).</li>
</ol>


<h3>Common arguments against this idea</h3>

<ol>
<li>Won&rsquo;t this reduce our ability to learn new tools and techniques?</li>
<li>I didn&rsquo;t say don&rsquo;t learn them&hellip;.learning is awesome! Just don&rsquo;t use them on a project unless they need to be used.</li>
<li>Things get cool because they are useful, not the other way around</li>
<li>Frankly, I think this is a rationalization for someone who has been seduced by the cool many times and doesn&rsquo;t want to admit their mistakes. There are many historical examples of this idea &ndash; i.e. I suppose in the 30&rsquo;s in Germany, it was pretty damn cool to be a Nazi.</li>
<li>Avoid the extremes of depth or breadth, and don&rsquo;t concern yourself with this complain. A happy median is what&rsquo;s really best!</li>
<li>Please see the first header in this post &ldquo;The Answer:&rdquo; for a response to this.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Charles Is Watching...]]></title>
    <link href="http://yoursite.com/blog/2013/10/23/charles-is-watching-dot-dot-dot/"/>
    <updated>2013-10-23T18:25:00+03:00</updated>
    <id>http://yoursite.com/blog/2013/10/23/charles-is-watching-dot-dot-dot</id>
    <content type="html"><![CDATA[<h2>The Problem</h2>

<p>It all started on a dark and rainy Tuesday afternoon in San Francisco (though it&rsquo;s nearly always cloudy, so this isn&rsquo;t saying much). I was at work, right in the middle of figuring out some mildly interesting problem with a colleague, when I decided to glance at my computer to check for something we needed. This forced me to accidentally check my E-Mail, which is always a horrible idea. As usual, there was something there that caught my eye in a mostly negative way &ndash; it was an E-Mail from Charles, written in all caps, yelling at me for not turning in my time sheet yet. Don&rsquo;t get me wrong, Charles is an awesome guy&hellip;one of my favorites in the San Francisco office&hellip;I don&rsquo;t want to kill the messenger, he just happens to be the one who sends out the E-Mails that force me to worry about my time-sheet :).</p>

<p>The E-Mail specifically detailed all the reasons I was damaging ThoughtWorks&#8217; bank account, and its relationship with the client by not turning in my time-sheet on time last week. I was ruining everything&hellip;.the company was going to fall apart if I didn&rsquo;t turn it in that day&hellip;and not only that, but this was maybe the 4&#8217;th or 5&#8217;th time it has happened! It was a miracle ThoughtWorks had managed to survive up until that point with all the damage I had already done, I couldn&rsquo;t jeopardize my beloved company yet again by making my time sheet even LATER! But, I was in the middle of pairing, and I didn&rsquo;t want to suddenly leave the warm embrace of my <a href="http://www.youtube.com/watch?v=dYBjVTMUQY0">loving pair</a>, switching context completely for 10-15 minutes while I thought long and hard about how many hours I worked the week before. Decisions, decisions&hellip;</p>

<h2>If Only&hellip;</h2>

<p>If only I had some way to quickly remember how many hours I worked in the last week! Even when I manage to turn in my time sheet on time, think of how many batches of 5-10 minutes are wasted sitting around trying to remember hours worked?</p>

<ul>
<li>10 minutes every 2 weeks or <strong>20 minutes every month</strong></li>
<li>1 year working in ThoughtWorks, or <strong>12 months</strong></li>
<li>12 * 20 = 240 minutes a year, or that&rsquo;s <strong>4 hours of wasted time</strong> per year</li>
<li>2,500+ employees in ThoughtWorks makes that at LEAST <strong>10,000 hours of wasted time</strong> (that&rsquo;s <strong>416 days</strong>, or <strong>83 working weeks</strong> of collective time per year)</li>
</ul>


<p>And if that still doesn&rsquo;t sound like a lot, keep in mind it isn&rsquo;t including the likely significantly larger portion of time that is wasted switching out of and then back into context when solving a problem, dealing with (and wasting more time thinking about) people badgering us constantly about turning in our time sheets, and all the rest that is involved. They didn&rsquo;t hire us at ThoughtWorks because of our awesome remembering hours worked abilities, but for other, potentially more useful skills they saw in us. So, I wanted some way to be able to quickly get past this issue.</p>

<p>At first, I wasn&rsquo;t sure how to accomplish this, but I had a hunch that being connected to the wifi (since we are nearly always on the internet at work) might be a good place to start. Ended up making a ruby script that keeps track of your time based on when you&rsquo;re connected to work wifi networks.</p>

<h2>So, how does it work?</h2>

<ol>
<li>Every 5 seconds or so, it checks to see if you&rsquo;re connected to one of the predefined wifi networks (by default, these are &lsquo;twdata&rsquo; and &lsquo;twguest&rsquo; &ndash; but can also easily add project specific wifi&rsquo;s.) Every 5 seconds when it checks, if you are detected being on the work networks you have defined (i.e.  you&rsquo;re &lsquo;at work&rsquo; to Charles) one of two things can happen:

<ol>
<li>If it is the first time Charles has been run for this day, he will create a new day starting at the current time (i.e. if you&rsquo;ve just arrived at work and opened your computer at 8:00am letting it connect to the wifi, it will mark 8:00am as the &ldquo;started work&rdquo; time for today.)</li>
<li>If you are detected as being connected to the network and Charles has already logged a starting time for that day, he will mark that time as the ENDING time for the day, replacing whatever the previous ending time was (if one existed).</li>
</ol>
</li>
</ol>


<p>This means every 5 seconds your &lsquo;ending time&rsquo; for the day is changing to be more up to date. The assumption is, the last time you close your computer and leave the office, that ending time will be accurately saved within 5 seconds.</p>

<p>You can see there may be a problem here, what if you close your computer at the middle of the day (or get disconnected from the wifi) does Charles just give up and assume you&rsquo;re no longer at work? No, he&rsquo;s not that stupid :-P</p>

<p>If you shut down your computer or disconnect from the wifi for a few hours at any time of the day, let&rsquo;s say you do this from 1pm to 2pm &ndash; Charles will mark the end of the day at 1pm. But then, as soon as you open the computer and it connects to the wifi again, as long as you still have Charles running, he will do this:</p>

<ol>
<li>Are we connected to the network? Yes.</li>
<li>OK, is it the first time I&rsquo;ve been connected today? Oh look, no it isn&rsquo;t, I&rsquo;ve already logged an ending time for today.</li>
<li>So that means they are probably still at work for today, let&rsquo;s mark 2pm as the new ending time.</li>
</ol>


<p>And he will continue along happily until you close your computer and go home for the day. You can connect to your home wifi all you want, because it is not in your &ldquo;Work SSID&rsquo;s list&rdquo;, so Charles will ignore it. The next day when you come to work, Charles will start a new day, and will remember almost exactly the time you left work on the previous day.</p>

<h2>Where Can I Get It?</h2>

<p>On <a href="https://github.com/Scatchell/Charles">Git Hub</a>, of course!</p>

<h2>The Future</h2>

<h4>Automating the Time Entry</h4>

<p>What I think would really be cool, is using a browser automation tool (like selenium) to give Charles a feature that allows it to log into our T&amp;E web page (if you already have a valid session) and set all the times automatically, taking out an hour or so for lunch automatically. Then, Charles would allow you to simply glance at the form it has automatically filled out, make sure everything is good and accurately represents what happened that week, and just click the submit button. Hopefully the whole process would take less than 15 seconds like this.</p>

<h4>Going Mobile</h4>

<p>Another option is to integrate Charles into a cell phone app. They are constantly searching for wifi networks, and since people tend to pretty much ALWAYS have their cell phones on, as long as you had your wifi activated on your mobile, this would probably be extremely accurate as far as logging exactly how many minutes you were inside of a particular building.</p>

<p>This could be accomplished quite easily, I think, if Charles were ported over to a small and simple web app library like Sinatra, and the cell phone could have an app that checks the wifi, and every time it is connected hit a route online that would log them as &ldquo;at work&rdquo;, allowing the Charles web app to handle the rest.</p>

<h4>Reasonable Display</h4>

<p>Right now, every time you start up Charles, he quickly lists all the previous days he remembers and the hours worked for those days. This could be a lot better, for instance showing the times only for the current week, and allowing movement backwards and forwards by week (maybe through a simple bootstrapped web-app :) )</p>

<h2>Known Issues</h2>

<h4>Wifi? Really?</h4>

<p>I realize wifi connection doesn&rsquo;t sound perfectly accurate at first glance, but in my experience it&rsquo;s been surprisingly representative of how long I&rsquo;ve been at work. However, forgetting to run the program, or never opening your computer on a certain day (maybe pairing with someone else the entire day? Or running around from meeting to meeting and never opening your computer one day?) is still an issue. I think the cell phone integration mentioned above could help greatly with this.</p>

<h4>Just a shitty ruby script? Really?</h4>

<p>It would also help a lot to have Charles be a real program, that can be run more easily through the GUI in the background, instead of a simply ruby script that still doesn&rsquo;t have any way to exit except hitting ctrl-c :-P</p>

<h4>The annoying people that make the rest of us look bad</h4>

<p>For you SUPER hard workers, I&rsquo;ve also noticed some bugs when staying past midnight for an event or something. When it gets past midnight, Charles gets extremely confused and ends the current day, immediately starting the next one at 12:00:01am, so then when you get to work the next day it thinks you&rsquo;ve already worked for 8 or 9 hours as soon as you walk in the door. I&rsquo;ve got some ideas on how to fix this, but it hasn&rsquo;t been a huge problem for me yet so haven&rsquo;t quite gotten around to it.</p>

<h4>Interested?</h4>

<p>Feel free to contact me with suggestions, ideas, interest in working on this mini project, or questions in general. Definitely interested to hear both the good and bad comments :)</p>
]]></content>
  </entry>
  
</feed>
